# ğŸ¤– IntegraÃ§Ã£o de IA - Gemini vs OpenAI

**Data:** 10 de outubro de 2025  
**VersÃ£o:** 1.0

---

## ğŸ¯ OpÃ§Ãµes de IA DisponÃ­veis

### 1. **Google Gemini** (Recomendado) â­
### 2. **OpenAI (GPT-4/GPT-3.5)**
### 3. **Ambos em Conjunto** (Best of Both Worlds)

---

## ğŸ“Š ComparaÃ§Ã£o RÃ¡pida

| Aspecto | Google Gemini | OpenAI GPT-4 |
|---------|--------------|--------------|
| **Custo** | ğŸ’°ğŸ’° Mais barato | ğŸ’°ğŸ’°ğŸ’° Mais caro |
| **Velocidade** | âš¡âš¡âš¡ Muito rÃ¡pido | âš¡âš¡ MÃ©dio |
| **Qualidade** | â­â­â­â­ Excelente | â­â­â­â­â­ Top |
| **Contexto** | 1M tokens (Gemini 1.5) | 128K tokens (GPT-4) |
| **Multimodal** | âœ… Nativo (texto+imagem+vÃ­deo) | âœ… Texto + imagem |
| **Idiomas** | âœ… Excelente em PT-BR | âœ… Muito bom em PT-BR |
| **N8N** | âœ… NÃ³ nativo | âœ… NÃ³ nativo |
| **API** | Google Cloud / AI Studio | OpenAI Platform |
| **GrÃ¡tis** | âœ… Tier gratuito generoso | âŒ SÃ³ pago |

---

## ğŸ’° ComparaÃ§Ã£o de Custos

### AnÃ¡lise de Sentimento (tarefa tÃ­pica)

**CenÃ¡rio:** 1000 colaboradores, 20 mensagens/dia cada, 30 dias

**Total:** 600.000 mensagens/mÃªs

#### Com Google Gemini 1.5 Flash (Recomendado)

```
Input: ~100 tokens/mensagem
Output: ~50 tokens/resposta

Custo Gemini 1.5 Flash:
- Input: $0.075 / 1M tokens
- Output: $0.30 / 1M tokens

CÃ¡lculo:
- Input: (600k Ã— 100) / 1M Ã— $0.075 = $4.50
- Output: (600k Ã— 50) / 1M Ã— $0.30 = $9.00

Total: ~$13.50/mÃªs âœ…
```

#### Com OpenAI GPT-3.5 Turbo

```
Custo GPT-3.5 Turbo:
- Input: $0.50 / 1M tokens
- Output: $1.50 / 1M tokens

CÃ¡lculo:
- Input: (600k Ã— 100) / 1M Ã— $0.50 = $30.00
- Output: (600k Ã— 50) / 1M Ã— $1.50 = $45.00

Total: ~$75/mÃªs âš ï¸
```

#### Com OpenAI GPT-4o

```
Custo GPT-4o:
- Input: $2.50 / 1M tokens
- Output: $10.00 / 1M tokens

CÃ¡lculo:
- Input: (600k Ã— 100) / 1M Ã— $2.50 = $150.00
- Output: (600k Ã— 50) / 1M Ã— $10.00 = $300.00

Total: ~$450/mÃªs ğŸ’¸
```

**Resultado:** Gemini Ã© **5-30x mais barato!** ğŸ‰

---

## ğŸ¯ RecomendaÃ§Ã£o de Uso

### **OpÃ§Ã£o 1: 100% Gemini** (Mais barato) ğŸ’°

```
Todas as tarefas com Gemini:
âœ… AnÃ¡lise de sentimento â†’ Gemini 1.5 Flash
âœ… GeraÃ§Ã£o de respostas â†’ Gemini 1.5 Flash
âœ… ExtraÃ§Ã£o de contexto â†’ Gemini 1.5 Flash
âœ… AnÃ¡lise de padrÃµes â†’ Gemini 1.5 Pro
âœ… GeraÃ§Ã£o de melhorias â†’ Gemini 1.5 Pro

Custo estimado: $15-30/mÃªs
```

---

### **OpÃ§Ã£o 2: HÃ­brido (Gemini + OpenAI)** (EquilÃ­brio) âš–ï¸

```
Tarefas simples â†’ Gemini 1.5 Flash (barato e rÃ¡pido)
âœ… AnÃ¡lise de sentimento
âœ… ExtraÃ§Ã£o de tags
âœ… DetecÃ§Ã£o de intenÃ§Ã£o

Tarefas complexas â†’ GPT-4o (mais preciso)
âœ… GeraÃ§Ã£o de melhorias complexas
âœ… AnÃ¡lise de padrÃµes sofisticados
âœ… Respostas muito contextualizadas

Custo estimado: $40-80/mÃªs
```

---

### **OpÃ§Ã£o 3: 100% OpenAI** (Mais qualidade) â­

```
Todas as tarefas com OpenAI:
âœ… AnÃ¡lise de sentimento â†’ GPT-3.5 Turbo
âœ… GeraÃ§Ã£o de respostas â†’ GPT-4o
âœ… AnÃ¡lise de padrÃµes â†’ GPT-4o
âœ… GeraÃ§Ã£o de melhorias â†’ GPT-4o

Custo estimado: $200-500/mÃªs
```

---

## ğŸ”§ ImplementaÃ§Ã£o no N8N

### 1. AnÃ¡lise de Sentimento com Gemini

#### Passo 1: Criar Credencial do Gemini

1. Acesse [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Crie uma API Key
3. No N8N: Credentials â†’ Add â†’ Google Gemini
4. Cole a API Key

#### Passo 2: Node do Gemini no N8N

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Gemini Chat Model             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Model: gemini-1.5-flash               â”‚
â”‚  Messages:                             â”‚
â”‚    System: VocÃª Ã© um analisador...    â”‚
â”‚    User: {{ $json.mensagem }}         â”‚
â”‚  Options:                              â”‚
â”‚    Temperature: 0.3                    â”‚
â”‚    Max Tokens: 150                     â”‚
â”‚    Response Format: JSON               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Prompt para AnÃ¡lise de Sentimento

```javascript
// System Message
`VocÃª Ã© um analisador de sentimentos especializado em onboarding.

Analise a mensagem do colaborador e retorne um JSON com:
- sentimento: "muito_positivo" | "positivo" | "neutro" | "negativo" | "muito_negativo"
- intensidade: nÃºmero de 0.00 a 1.00
- fatores_detectados: {
    palavras_chave: array de strings,
    tom: string,
    emojis: array de emojis encontrados
  }

Seja preciso e considere o contexto de onboarding empresarial.`

// User Message
`Mensagem do colaborador: "${mensagem}"`

// Resposta esperada (JSON)
{
  "sentimento": "negativo",
  "intensidade": 0.72,
  "fatores_detectados": {
    "palavras_chave": ["difÃ­cil", "nÃ£o sei", "conseguir"],
    "tom": "inseguro",
    "emojis": ["ğŸ˜•"]
  }
}
```

---

### 2. GeraÃ§Ã£o de Respostas com Gemini

```javascript
// System Message
`VocÃª Ã© o assistente virtual Flowly, especializado em onboarding.

VocÃª deve:
- Ser empÃ¡tico e acolhedor
- Adaptar o tom baseado no sentimento do colaborador
- Ser objetivo e claro
- Usar emojis moderadamente

Sentimento atual do colaborador: ${sentimento}

Regras por sentimento:
- muito_negativo: Muito empÃ¡tico, oferecer ajuda imediata
- negativo: Compreensivo, dar suporte
- neutro: Profissional padrÃ£o
- positivo: Motivador, reconhecer esforÃ§o
- muito_positivo: Celebrativo, parabenizar`

// User Message
`Colaborador perguntou: "${mensagem}"

${trilhasRecomendadas ? `Trilhas disponÃ­veis: ${JSON.stringify(trilhas)}` : ''}`

// Resposta serÃ¡ gerada pelo Gemini
```

---

### 3. Workflow N8N Completo com Gemini

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  WORKFLOW: Conversa IA                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                          â”‚
â”‚  1ï¸âƒ£ Webhook Trigger                                     â”‚
â”‚     â†“                                                    â”‚
â”‚  2ï¸âƒ£ HTTP Request - Buscar Dados do UsuÃ¡rio             â”‚
â”‚     GET /api/users/{{$json.user_id}}                    â”‚
â”‚     â†“                                                    â”‚
â”‚  3ï¸âƒ£ Google Gemini - AnÃ¡lise de Sentimento              â”‚
â”‚     Model: gemini-1.5-flash                             â”‚
â”‚     Prompt: Analisar sentimento da mensagem             â”‚
â”‚     â†“                                                    â”‚
â”‚  4ï¸âƒ£ Code - Parse JSON do Gemini                        â”‚
â”‚     â†“                                                    â”‚
â”‚  5ï¸âƒ£ HTTP Request - Salvar Sentimento                   â”‚
â”‚     POST /api/sentimentos                               â”‚
â”‚     â†“                                                    â”‚
â”‚  6ï¸âƒ£ Switch - Detectar IntenÃ§Ã£o                         â”‚
â”‚     â”œâ”€ Pediu trilhas â†’ 7A                              â”‚
â”‚     â”œâ”€ DÃºvida â†’ 7B                                     â”‚
â”‚     â””â”€ Feedback â†’ 7C                                   â”‚
â”‚     â†“                                                    â”‚
â”‚  7Aï¸âƒ£ HTTP Request - Buscar Trilhas Recomendadas        â”‚
â”‚     GET /api/trilhas/recomendadas/{{user_id}}          â”‚
â”‚     â†“                                                    â”‚
â”‚  8ï¸âƒ£ Google Gemini - Gerar Resposta                     â”‚
â”‚     Model: gemini-1.5-flash                             â”‚
â”‚     Context: Sentimento + Trilhas                       â”‚
â”‚     â†“                                                    â”‚
â”‚  9ï¸âƒ£ WhatsApp - Enviar Mensagem                         â”‚
â”‚                                                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”Œ CÃ³digo de IntegraÃ§Ã£o

### Gemini via API REST (alternativa ao N8N)

```javascript
// src/services/gemini-service.js

const { GoogleGenerativeAI } = require("@google/generative-ai");

class GeminiService {
  constructor() {
    this.genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
  }
  
  async analisarSentimento(mensagem) {
    const model = this.genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    const prompt = `
      Analise o sentimento desta mensagem de onboarding e retorne JSON:
      
      Mensagem: "${mensagem}"
      
      Formato de resposta:
      {
        "sentimento": "muito_positivo|positivo|neutro|negativo|muito_negativo",
        "intensidade": 0.00-1.00,
        "fatores_detectados": {
          "palavras_chave": [],
          "tom": "",
          "emojis": []
        }
      }
    `;
    
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    // Parse JSON da resposta
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
    
    throw new Error('Resposta invÃ¡lida do Gemini');
  }
  
  async gerarResposta({ mensagem, sentimento, contexto }) {
    const model = this.genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    const systemPrompt = `
      VocÃª Ã© o assistente Flowly de onboarding.
      Sentimento do colaborador: ${sentimento}
      Adapte o tom conforme o sentimento.
    `;
    
    const userPrompt = `
      ${systemPrompt}
      
      Colaborador: "${mensagem}"
      
      ${contexto.trilhas ? `Trilhas disponÃ­veis: ${JSON.stringify(contexto.trilhas)}` : ''}
      
      Gere uma resposta empÃ¡tica e Ãºtil.
    `;
    
    const result = await model.generateContent(userPrompt);
    const response = await result.response;
    
    return response.text();
  }
  
  async extrairTags(anotacao) {
    const model = this.genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
    
    const prompt = `
      Extraia tags relevantes desta anotaÃ§Ã£o de onboarding:
      
      "${anotacao}"
      
      Retorne um array JSON de tags (mÃ¡x 5):
      ["tag1", "tag2", "tag3"]
    `;
    
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    const jsonMatch = text.match(/\[[\s\S]*\]/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
    
    return [];
  }
  
  async analisarPadroes(anotacoes) {
    const model = this.genAI.getGenerativeModel({ 
      model: "gemini-1.5-pro" // Pro para anÃ¡lises mais complexas
    });
    
    const prompt = `
      Analise estes feedbacks de onboarding e identifique padrÃµes:
      
      ${anotacoes.map(a => `- ${a.titulo}: ${a.anotacao}`).join('\n')}
      
      Retorne JSON com:
      {
        "padroes_identificados": [
          {
            "titulo": "",
            "descricao": "",
            "frequencia": 0,
            "impacto": "baixo|medio|alto"
          }
        ],
        "sugestoes_melhoria": [
          {
            "titulo": "",
            "descricao": "",
            "prioridade": "baixa|media|alta|critica",
            "impacto_estimado": "baixo|medio|alto|muito_alto"
          }
        ]
      }
    `;
    
    const result = await model.generateContent(prompt);
    const response = await result.response;
    const text = response.text();
    
    const jsonMatch = text.match(/\{[\s\S]*\}/);
    if (jsonMatch) {
      return JSON.parse(jsonMatch[0]);
    }
    
    throw new Error('Resposta invÃ¡lida do Gemini');
  }
}

module.exports = GeminiService;
```

### Uso no Backend

```javascript
// src/routes/ai.js

const GeminiService = require('../services/gemini-service');
const gemini = new GeminiService();

router.post('/api/ai/conversa', async (req, res) => {
  const { user_id, mensagem } = req.body;
  
  try {
    // 1. Analisar sentimento
    const sentimento = await gemini.analisarSentimento(mensagem);
    
    // 2. Salvar sentimento no banco
    await db.query(`
      INSERT INTO colaborador_sentimentos (...)
      VALUES (...)
    `, [user_id, sentimento.sentimento, sentimento.intensidade]);
    
    // 3. Buscar trilhas recomendadas
    const trilhas = await db.query(`
      SELECT * FROM buscar_trilhas_por_sentimento($1, $2, 3)
    `, [user_id, sentimento.sentimento]);
    
    // 4. Gerar resposta
    const resposta = await gemini.gerarResposta({
      mensagem,
      sentimento: sentimento.sentimento,
      contexto: { trilhas: trilhas.rows }
    });
    
    res.json({
      resposta,
      sentimento: sentimento.sentimento,
      trilhas: trilhas.rows
    });
    
  } catch (error) {
    console.error('Erro ao processar conversa:', error);
    res.status(500).json({ error: 'Erro ao processar mensagem' });
  }
});
```

---

## ğŸ“¦ DependÃªncias

### Para usar Gemini no Node.js

```bash
npm install @google/generative-ai
```

```javascript
// package.json
{
  "dependencies": {
    "@google/generative-ai": "^0.21.0"
  }
}
```

### VariÃ¡veis de Ambiente

```bash
# .env
GEMINI_API_KEY=AIzaSy...
```

---

## ğŸ¯ EstratÃ©gia HÃ­brida (Recomendado)

### Usar Gemini para:
âœ… **AnÃ¡lise de Sentimento** (rÃ¡pido e barato)  
âœ… **GeraÃ§Ã£o de Respostas Simples** (conversas do dia a dia)  
âœ… **ExtraÃ§Ã£o de Tags** (processamento rÃ¡pido)  
âœ… **ClassificaÃ§Ã£o de IntenÃ§Ã£o** (simples)  

### Usar OpenAI para:
âœ… **AnÃ¡lise de PadrÃµes Complexos** (quando precisar de mais contexto)  
âœ… **GeraÃ§Ã£o de Melhorias Detalhadas** (mais criativo)  
âœ… **Respostas Muito Contextualizadas** (casos especiais)  

### CÃ³digo de DecisÃ£o

```javascript
class AIRouter {
  constructor() {
    this.gemini = new GeminiService();
    this.openai = new OpenAIService();
  }
  
  async analisarSentimento(mensagem) {
    // Sempre usar Gemini (mais barato)
    return await this.gemini.analisarSentimento(mensagem);
  }
  
  async gerarResposta({ mensagem, sentimento, complexidade }) {
    // Se simples â†’ Gemini
    if (complexidade === 'simples' || complexidade === 'media') {
      return await this.gemini.gerarResposta({ mensagem, sentimento });
    }
    
    // Se complexa â†’ OpenAI
    return await this.openai.gerarResposta({ mensagem, sentimento });
  }
  
  async analisarPadroes(anotacoes) {
    // Se poucas anotaÃ§Ãµes â†’ Gemini
    if (anotacoes.length < 10) {
      return await this.gemini.analisarPadroes(anotacoes);
    }
    
    // Se muitas anotaÃ§Ãµes â†’ OpenAI (contexto maior)
    return await this.openai.analisarPadroes(anotacoes);
  }
}
```

---

## ğŸ”’ SeguranÃ§a

### Gemini
```javascript
// Proteger API Key
process.env.GEMINI_API_KEY

// Rate limiting
const rateLimit = require('express-rate-limit');
const limiter = rateLimit({
  windowMs: 1 * 60 * 1000, // 1 minuto
  max: 100 // max 100 requests por minuto
});
```

### OpenAI
```javascript
// Proteger API Key
process.env.OPENAI_API_KEY

// Mesmas prÃ¡ticas de rate limiting
```

---

## ğŸ“Š Monitoramento de Custos

### Dashboard de Uso

```javascript
// src/services/ai-usage-tracker.js

class AIUsageTracker {
  async track(provider, operation, tokens) {
    await db.query(`
      INSERT INTO ai_usage_log (
        provider, operation, tokens_used, cost_usd, created_at
      ) VALUES ($1, $2, $3, $4, NOW())
    `, [
      provider, // 'gemini' ou 'openai'
      operation, // 'sentiment', 'response', 'pattern'
      tokens,
      this.calculateCost(provider, tokens)
    ]);
  }
  
  calculateCost(provider, tokens) {
    const costs = {
      'gemini-flash': 0.075 / 1000000, // por token
      'gemini-pro': 1.25 / 1000000,
      'gpt-3.5': 0.50 / 1000000,
      'gpt-4o': 2.50 / 1000000
    };
    
    return tokens * costs[provider];
  }
  
  async getMonthlyReport() {
    const result = await db.query(`
      SELECT 
        provider,
        SUM(tokens_used) as total_tokens,
        SUM(cost_usd) as total_cost,
        COUNT(*) as total_requests
      FROM ai_usage_log
      WHERE created_at >= DATE_TRUNC('month', NOW())
      GROUP BY provider
    `);
    
    return result.rows;
  }
}
```

---

## âœ… RecomendaÃ§Ã£o Final

### **Para o Flowly: Use Gemini!** ğŸ¯

**Motivos:**
1. âœ… **Custo 5-30x menor**
2. âœ… **Qualidade excelente** para as tarefas necessÃ¡rias
3. âœ… **PortuguÃªs nativo** muito bom
4. âœ… **Contexto gigante** (1M tokens no Gemini 1.5)
5. âœ… **Tier gratuito** para testar
6. âœ… **IntegraÃ§Ã£o fÃ¡cil** com N8N

### Setup Inicial Recomendado:

```
ğŸ¯ AnÃ¡lise de Sentimento: Gemini 1.5 Flash
ğŸ¯ GeraÃ§Ã£o de Respostas: Gemini 1.5 Flash  
ğŸ¯ ExtraÃ§Ã£o de Tags: Gemini 1.5 Flash
ğŸ¯ AnÃ¡lise de PadrÃµes: Gemini 1.5 Pro

Custo estimado: $15-30/mÃªs
Performance: Excelente
Qualidade: Muito boa
```

### Se precisar de mais qualidade depois:
Adicione OpenAI GPT-4o para casos especÃ­ficos (anÃ¡lises muito complexas).

---

**Criado por:** Haendell Lopes + AI Assistant  
**Data:** 10 de outubro de 2025  
**Status:** âœ… Pronto para ImplementaÃ§Ã£o




